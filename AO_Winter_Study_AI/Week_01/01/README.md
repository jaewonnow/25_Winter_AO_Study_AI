### 🎤 발표 핵심

- Model = 함수? 시스템?
- 입력 → 출력 → 파라미터 → Loss
- 학습 vs 추론 차이
- Overfitting / Generalization

---

## Model 이란?

> **'모형, 본보기, 견본'** 이라는 기본 뜻에서 확장  
> → 현실의 복잡한 대상을 **단순화해서 다루기 위한 구조**

머신러닝에서 모델은 **함수**일 수도 있고 **시스템**일 수도 있다.

---

## 🔢 수학/머신러닝 이론 관점: 모델 = 함수

- 모델은 입력을 받으면 출력을 내는 **함수**
- 입력 `x` → 출력 `y`를 예측하는 규칙
- "이 특징(입력)이 들어오면 이런 결과(출력)가 나올 확률이 크다" 같은 관계를 표현

### 예시: 퍼셉트론

- 입력들의 **가중합(weighted sum)** 을 만들고
- 어떤 기준(임계값)을 넘으면 `1`, 아니면 `0`

---

## 🛠️ 서비스/제품 관점: 모델 = 시스템

- 배포/서빙, 모니터링, 로깅, 재학습까지 포함한 **운영 가능한 예측 시스템**
- 모델 함수뿐만 아니라 주변 구성 전체를 의미:
  - 입력 → 전처리 → 핵심 추론 → 후처리 → 배포 → 모니터링

> **예시:**  
> 사용자의 감정을 얼굴 표정으로 인식하는 앱을 만들고 싶다면?  
> → 감정 라벨이 붙은 얼굴 이미지 데이터를 모아 모델을 학습  
> → 학습된 모델은 새로운 사용자 얼굴이 들어왔을 때도 감정을 예측

---

## 모델 학습의 핵심 구조

```
입력 → 모델 → 출력 → 손실(Loss)
```

### 1️⃣ 입력 (Input)

모델에 넣는 데이터(특징)

### 2️⃣ 파라미터 (Parameters)

모델 내부 숫자들 — **모델이 배우는 것의 실체**

| 구분                | 설명                                                |
| ------------------- | --------------------------------------------------- |
| **가중치 (Weight)** | 각 입력 특징을 얼마나 중요하게 볼지 정하는 "다이얼" |
| **편향 (Bias)**     | 결과를 전체적으로 밀어주는 "기본 오프셋(보정값)"    |

```
z = w·x + b
```

- 입력값에 가중치를 곱하고 편향을 더해 결과를 냄
- AI 모델의 학습 = **가중치와 편향을 적절히 조율하는 과정**

### 3️⃣ 활성화 함수 (Activation Function)

- 파라미터의 선형 결과(`z`)를 그대로 출력하면 **선형(직선) 관계**만 표현 가능
- 현실 데이터는 복잡 → **활성화 함수로 비선형성 추가**

### 4️⃣ 출력 (Output)

모델이 낸 **예측값**

### 5️⃣ 손실 (Loss)

예측과 정답의 차이를 수치화한 값

| 손실 값  | 의미        | 대응                 |
| -------- | ----------- | -------------------- |
| **크다** | 많이 틀렸다 | 파라미터를 크게 수정 |
| **작다** | 덜 틀렸다   | 조금만 수정          |

### 6️⃣ 역전파 (Backpropagation)

> _"각 파라미터가 손실에 얼마나 책임 있는지"_ → **기울기(gradient)** 계산

- **연쇄법칙(Chain Rule)** 사용
- 손실 `L`의 영향을 출력층 → 입력층 방향으로 전달
- 각 레이어의 파라미터가 손실에 미친 영향(미분값) 계산

### 7️⃣ 최적화 (Optimization)

역전파가 계산한 기울기를 재료로 **파라미터 업데이트**

#### 경사 하강법 (Gradient Descent)

- 기울기를 보고 _"파라미터를 실제로 어떻게 바꿀지"_ 결정
- 기울기가 양수면 → 음수 방향으로 weight 수정
- **minima에 도달할 때까지 반복**

---

## 학습(Training) vs 추론(Inference)

### 학습 (Training)

방대한 양의 데이터와 정답(라벨) 필요

```
파라미터 조정 → 활성화 함수로 신호 변환 → 손실 함수로 오차 확인 → 최적화 알고리즘으로 수정 → 반복
```

- 모델이 예측하고 손실을 계산
- 역전파로 파라미터를 계속 업데이트
- 반복 학습을 통해 **일반화 성능**을 키움

### 추론 (Inference)

- 학습이 끝난 모델을 사용해 새 입력에 대한 결과 도출
- **파라미터가 고정**됨
- 보통 **순방향 계산만** 수행

---

## Underfit vs Optimum vs Overfit

> (사진)
> 주황/파랑 점 = 서로 다른 클래스  
> 가운데 선 = 결정 경계 (모델이 입력을 클래스별로 구분하는 기준선)

| 상태         | 특징                     | 훈련 오차 | 테스트 오차 | 원인                             |
| ------------ | ------------------------ | --------- | ----------- | -------------------------------- |
| **Underfit** | 경계가 너무 단순         | 높음      | 높음        | 모델이 너무 단순하거나 학습 부족 |
| **Optimum**  | 경계가 적당히 휘어짐     | 낮음      | 낮음        | 일반화(generalization) 성공      |
| **Overfit**  | 경계가 지나치게 구불구불 | 낮음      | 높음        | 모델이 훈련 데이터를 암기        |

### 🔻 Underfit (과소적합)

- **High Bias (높은 편향):** 데이터를 조금 바꿔도 결정 경계가 거의 그대로
- 데이터 패턴을 제대로 학습하지 못함

### ✅ Optimum (적정 모델)

- 필요한 만큼만 적당히 휘어져서 실제 분포를 잘 나눔
- **일반화:** 훈련 데이터뿐만 아니라 새로운 데이터도 잘 예측

### 🔺 Overfit (과적합)

- **High Variance (높은 변동):** 데이터를 조금 바꾸면 결정 경계가 확 바뀜
- 훈련 데이터의 **노이즈까지 외워버림**
- 훈련 데이터에는 완벽하지만, 새 데이터에는 약함

---

## 참고 자료

- [훈련/추론 다이어그램](https://quadcube.tistory.com/140)
- [Overfitting & Generalization](https://www.exxactcorp.com/blog/deep-learning/overfitting-generalization-the-bias-variance-tradeoff)
  등등
